# =============================================================================
# Ryumem Configuration Template
# Copy this file to .env and fill in your actual values
# =============================================================================
#
# # =============================================================================
# # Database Configuration
# # =============================================================================

# Path to the ryugraph database folder (will contain {customer_id}.db files)
RYUMEM_DB_FOLDER=./data

# Admin API Key for registering new customers
ADMIN_API_KEY=change_this_to_a_secure_random_string

# =============================================================================
# Background Worker Configuration
# =============================================================================
# These settings control the background worker for entity extraction

# Enable background worker for entity extraction (default: true)
# When enabled, entity extraction is offloaded to a separate worker process
RYUMEM_WORKER_ENABLED=true

# Redis URL for job queue (required if worker is enabled)
REDIS_URL=redis://localhost:6379

# Shared secret for internal worker endpoints
# The worker uses this to authenticate when calling back to the server
WORKER_INTERNAL_KEY=change_this_to_a_secure_random_string

# Server URL for worker callbacks (default: http://localhost:8000)
# The worker calls this URL to persist extracted entities/relationships
SERVER_URL=http://localhost:8000

# =============================================================================
# LLM & Embedding Provider Configuration
# =============================================================================
# Supported providers: gemini (default), openai, ollama, litellm

# LLM provider for entity extraction (default: gemini)
LLM_PROVIDER=gemini

# Embedding provider for similarity search (default: gemini)
EMBEDDING_PROVIDER=gemini

# =============================================================================
# Google Gemini Configuration (Default)
# =============================================================================
# Required when LLM_PROVIDER=gemini or EMBEDDING_PROVIDER=gemini

# Google API key for Gemini models
GOOGLE_API_KEY=your-google-api-key

# Gemini LLM model (default: gemini-2.0-flash-exp)
# Options: gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash
LLM_MODEL=gemini-2.0-flash-exp

# Gemini embedding model (default: text-embedding-004)
EMBEDDING_MODEL=text-embedding-004

# Embedding dimensions for Gemini (default: 768)
EMBEDDING_DIMENSIONS=768

# =============================================================================
# OpenAI Configuration (Alternative)
# =============================================================================
# Required when LLM_PROVIDER=openai or EMBEDDING_PROVIDER=openai
# Uncomment and configure if using OpenAI instead of Gemini

# OPENAI_API_KEY=sk-your-openai-api-key
# LLM_PROVIDER=openai
# EMBEDDING_PROVIDER=openai
# LLM_MODEL=gpt-4
# EMBEDDING_MODEL=text-embedding-3-large
# EMBEDDING_DIMENSIONS=3072

# =============================================================================
# Ollama Configuration (Local/Self-hosted)
# =============================================================================
# Use for local inference without API costs
# Uncomment and configure if using Ollama

# LLM_PROVIDER=ollama
# EMBEDDING_PROVIDER=ollama
# OLLAMA_BASE_URL=http://localhost:11434
# LLM_MODEL=qwen2.5:7b
# EMBEDDING_MODEL=nomic-embed-text
# EMBEDDING_DIMENSIONS=768
